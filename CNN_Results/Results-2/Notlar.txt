def build_classifier():
    
    classifier = Sequential()
    
    classifier.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', 
                          kernel_initializer = 'he_normal',
                          padding = 'same', input_shape = (28,28,1)))
    classifier.add(MaxPool2D(pool_size = (2, 2), padding = 'same'))
    classifier.add(BatchNormalization())
    classifier.add(Dropout(0.25))
    
    classifier.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', 
                          padding = 'same'))
    classifier.add(MaxPool2D(pool_size = (2, 2), padding = 'same'))
    classifier.add(BatchNormalization())
    classifier.add(Dropout(0.25))
    
    classifier.add(Conv2D(filters = 256, kernel_size = (3, 3), activation = 'relu', 
                          padding = 'same'))
    classifier.add(MaxPool2D(pool_size = (2, 2), padding = 'same'))
    classifier.add(BatchNormalization())
    classifier.add(Dropout(0.4))
    
    classifier.add(Flatten())
    classifier.add(Dense(128, activation = 'relu', kernel_constraint = unit_norm()))
    classifier.add(BatchNormalization())
    classifier.add(Dropout(0.2))
    classifier.add(Dense(10, activation = 'softmax'))
                   
    #opt = Adam()
    opt = SGD()
    #opt = RMSprop()
    
    classifier.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])
    
    plot_model(classifier, to_file='model_plot.png', show_shapes=True, show_layer_names=True)
    
    return classifier

epochs = 50
datagen = ImageDataGenerator()

Not: İnternette yapılan belli araştırmalar sonucunda İkinci CNN modelinde convolution katman sayısı 3'e çıkarıldı. 
Filtre sayıları büyük ölçüde arttırıldı. Optimizer SGD olarak değiştirildi. Dropout değerleriyle oynandı. Fully connected 
kısmı tek bir katmana indirildi. Sonuçları incelemeden önce belirtilmesi gereken noktalardan biri data augmentation operasyonu. 
ImageDataGenerator fonksiyonunu çağırırken içindeki rotation, shift gibi parametrelerle oynamak accuracy'e zarar veriyor. Bunun 
nedeni test edilecek verisetinde train verisetindeki gibi bu oynamalar sonucu pozisyon yapılardında değişiklik içeren 
(örneğin resmin yana yatması, şeklinin sağa veya sola kaydırılması gibi) resimler içermemisyle alakalı olabileceğini düşünüyorum. 
Test veriseti gözlemlendiği kadarıyla belli bir yapıya sahip şekilde sadece düz bir şekilde ortalanmış resimlerden oluştuğu 
için data augmentation yaparken parametre verildiği zaman train veriseti daha geniş özellikteki resimlere hitap edeceğinden 
eğitilen model sadece düz resimlere odaklanmayacak aynı zamanda değişik yapılarda olan bu görselleri içeren resimleri de hesaba
katacaktır. Dolayısıyla düz resimler çok fazla eğitilmediği için accuracy'de düşüş söz konusu olacaktır. Bu durum data 
augmentation yaparken verisetine çok fazla sayıda düz resim içeren verilerin türetilmesiyle ortadan kalkabilecektir diye 
düşünüyorum. Ancak zamanım kısıtlı olduğu için bu alana çok fazla şimdilik girmediğimi bu yüzden sadece düz resimlerin 
yapılarında resimlerin düz kalmasını sağlayacak şekilde oynamalar yaparak yani parametre vermeden data augmentation işlemini 
uyguladığımı belirtmeliyim. 50 epoch'ta eğitilen bu ikinci model grafikten de anlaşılacağı üzere bir önceki modele göre daha 
istikrarlı bir performans sergilemiş durumda. Test verisetinde alınan sonuçlar da ortalama %93'ü görmüş durumda. Bir önceki 
modele göre bu modelin daha kararlı bir şekilde kendini eğittiğini sonuçlardan da görebiliyoruz. Accuracy değeri, 
validation data üzerinde %93'ü gördükten sonra artık kolay kolay ileriki iterasyonlarda bu değerin altına düşmüyor tam tersine 
daha kararlı bir şekilde bu değeri korumayı başarıyor. Yine de belli ölçüde dalgalanmalar ortaya çıkmış olsa da bu çok doğal 
bir durumdur. Önemli olan biraz daha kararlı ve olumlu yönde ilerleyen bir yapıya ulaşabilmekti ve bu ikinci deneyde bunun 
çok iyi bir derecede başarıldığını söyleyebilirim. Eklenmesi gereken diğer bir nokta ise fully connected giriş 
katmanında uygulanan kernel_constraint = unit_norm() fonksiyonudur. Bu fonksiyon sinir ağındadaki ağırlıkların hacminin 
belirlenmiş bir limiti geçip geçmediğini kontrol eder. Eğer limit aşılmışsa bu ağırlıkları yeniden ölçeklendirir. Bu fonksiyon 
fully connected kısmının giriş katmanında uygulandığında modelin birazcık daha hızlı öğrendiği gözlemlenmiştir. Son olarak T-shirt-
lerin ayırt edilmesi beklenen seviyeye gelmiş ve ayırt edilmesi en zor resimlerden olan shirt resimleri yine de diğerlerine göre
daha düşük bir yüzdeyle ayırt edilse de accuracy değeri önceki modellere göre çok daha iyileştirilmiş ve diğer modellere göre 
en iyi sonuç alınarak beklenen accuracy değerine belli ölçüde ulaşılmıştır. 
 